{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ajAvgsnQ6PoK"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ed3pa-k9NVg"},"outputs":[],"source":["df = pd.read_csv(\"/content/sample_data/Customer_Churn.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzczOMhf90w-"},"outputs":[],"source":["df.info();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OtBWOzq-TOz"},"outputs":[],"source":["print(df.isnull().sum())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYpj7f-1-XUc"},"outputs":[],"source":["print(df['TotalCharges'].dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICJAvE2f-oSq"},"outputs":[],"source":["def assign_tenure_group(tenure):\n","    if tenure \u003c= 12:\n","        return 'Low'\n","    elif 13 \u003c= tenure \u003c= 36:\n","        return 'Medium'\n","    else:\n","        return 'High'\n","\n","df['TenureGroup'] = df['tenure'].apply(assign_tenure_group)\n","print(df['TenureGroup'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0fjF8IG-vlc"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aKAeFWc-64F"},"outputs":[],"source":["sns.set(style='whitegrid')\n","plt.figure(figsize=(8, 5))\n","sns.countplot(data=df, x='Contract', hue='Churn', palette='Set2')\n","plt.title('Churn by Contract Type')\n","plt.xlabel('Contract Type')\n","plt.ylabel('Customer Count')\n","plt.legend(title='Churn')\n","plt.xticks(rotation=15)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Io05yj0_G6c"},"outputs":[],"source":["categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n","print(categorical_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIo0ocRu_Jhz"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X = df.drop('Churn', axis=1)\n","y = df['Churn']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubAx6wYu_Sub"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmuksS1F_6eJ"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X = df.drop('Churn', axis=1)\n","y = df['Churn']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5qy4UH_ANok"},"outputs":[],"source":["df = df.drop(['customerID'], axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mO8nL-XDAPos"},"outputs":[],"source":["X = df.drop('Churn', axis=1)\n","y = df['Churn']\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epKfd_59ApS2"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKvVGZOlAqrV"},"outputs":[],"source":["if 'customerID' in df.columns:\n","    df = df.drop('customerID', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObvYRSmPAuE2"},"outputs":[],"source":["df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n","df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLCiqgYPAuBd"},"outputs":[],"source":["df['TenureGroup'] = pd.cut(df['tenure'],\n","                           bins=[0, 12, 36, df['tenure'].max()],\n","                           labels=['Low', 'Medium', 'High'],\n","                           include_lowest=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zIeVxm3CA39_"},"outputs":[],"source":["binary_cols = ['gender', 'Partner', 'Dependents', 'PhoneService',\n","               'PaperlessBilling', 'Churn']\n","le = LabelEncoder()\n","for col in binary_cols:\n","    df[col] = le.fit_transform(df[col])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyIFLLc4A6wn"},"outputs":[],"source":["multi_cat_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity',\n","                  'OnlineBackup', 'DeviceProtection', 'TechSupport',\n","                  'StreamingTV', 'StreamingMovies', 'Contract',\n","                  'PaymentMethod', 'TenureGroup']\n","\n","df = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9yYd3S8A7_h"},"outputs":[],"source":["scaler = MinMaxScaler()\n","df[['MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(df[['MonthlyCharges', 'TotalCharges']])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uXSQqi1HA-pB"},"outputs":[],"source":["X = df.drop('Churn', axis=1)\n","y = df['Churn']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipZ5XwzuBBYO"},"outputs":[],"source":["log_model = LogisticRegression(max_iter=1000)\n","log_model.fit(X_train, y_train)\n","\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOGrhz2mBEyz"},"outputs":[],"source":["def evaluate_model(name, model):\n","    y_pred = model.predict(X_test)\n","    print(f\" {name}\")\n","    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n","    print(\"Precision:\", precision_score(y_test, y_pred))\n","    print(\"Recall   :\", recall_score(y_test, y_pred))\n","    print(\"F1 Score :\", f1_score(y_test, y_pred))\n","    print(\"-\" * 40)\n","\n","evaluate_model(\"Logistic Regression\", log_model)\n","evaluate_model(\"Decision Tree\", dt_model)\n","evaluate_model(\"Random Forest\", rf_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyGatfE3BX2S"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def evaluate_model(name, model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    print(f\" {name} Evaluation\")\n","    print(\"Accuracy :\", round(accuracy_score(y_test, y_pred), 4))\n","    print(\"Precision:\", round(precision_score(y_test, y_pred), 4))\n","    print(\"Recall   :\", round(recall_score(y_test, y_pred), 4))\n","    print(\"F1 Score :\", round(f1_score(y_test, y_pred), 4))\n","    print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5z-nq4uBZ8R"},"outputs":[],"source":["evaluate_model(\"Logistic Regression\", log_model, X_test, y_test)\n","evaluate_model(\"Decision Tree\", dt_model, X_test, y_test)\n","evaluate_model(\"Random Forest\", rf_model, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXNRMfUiBdsn"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWmG_oIYBj3Y"},"outputs":[],"source":["param_grid_log = {\n","    'C': [0.01, 0.1, 1, 10],\n","    'solver': ['liblinear', 'lbfgs']\n","}\n","\n","param_grid_dt = {\n","    'criterion': ['gini', 'entropy'],\n","    'max_depth': [None, 5, 10],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","param_grid_rf = {\n","    'n_estimators': [50, 100],\n","    'max_depth': [None, 10],\n","    'min_samples_split': [2, 5]\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rV2SGOwcCdJj"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","\n","log_model = LogisticRegression(max_iter=1000)\n","grid_log = GridSearchCV(log_model, param_grid_log, cv=5, scoring='accuracy')\n","grid_log.fit(X_train, y_train)\n","\n","\n","dt_model = DecisionTreeClassifier()\n","grid_dt = GridSearchCV(dt_model, param_grid_dt, cv=5, scoring='accuracy')\n","grid_dt.fit(X_train, y_train)\n","\n","rf_model = RandomForestClassifier()\n","grid_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='accuracy')\n","grid_rf.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWO7WL8RDQQX"},"outputs":[],"source":["print(\"Best parameters for Logistic Regression:\", grid_log.best_params_)\n","print(\"Best accuracy for Logistic Regression:\", grid_log.best_score_)\n","\n","print(\"Best parameters for Decision Tree:\", grid_dt.best_params_)\n","print(\"Best accuracy for Decision Tree:\", grid_dt.best_score_)\n","\n","print(\"Best parameters for Random Forest:\", grid_rf.best_params_)\n","print(\"Best accuracy for Random Forest:\", grid_rf.best_score_)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NYE-nHSDSGc"},"outputs":[],"source":["dt_importances = pd.DataFrame({\n","    'Feature': X_train.columns,\n","    'Importance': grid_dt.best_estimator_.feature_importances_\n","}).sort_values(by='Importance', ascending=False)\n","rf_importances = pd.DataFrame({\n","    'Feature': X_train.columns,\n","    'Importance': grid_rf.best_estimator_.feature_importances_\n","}).sort_values(by='Importance', ascending=False)\n","\n","print(\"Important Features from Decision Tree:\\n\", dt_importances.head(10))\n","print(\"Important Features from Random Forest:\\n\", rf_importances.head(10))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ntZANM3FFQV-"},"outputs":[],"source":["df = pd.read_csv(\"/content/sample_data/Customer_Support_Tweets.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQ63cLgLFes2"},"outputs":[],"source":["df.info();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RvSSNLqRHMUr"},"outputs":[],"source":["print(df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUqlULRNH_mx"},"outputs":[],"source":["inbound_df = df[df['inbound'] == True].copy()\n","outbound_df = df[df['inbound'] == False].copy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qr1PvO_xID6t"},"outputs":[],"source":["merged_df = pd.merge(\n","    inbound_df,\n","    outbound_df[['in_response_to_tweet_id', 'created_at']],\n","    left_on='tweet_id',\n","    right_on='in_response_to_tweet_id',\n","    how='left',\n","    suffixes=('_inbound', '_response')\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiGVPaU7IHyZ"},"outputs":[],"source":["merged_df['created_at_inbound'] = pd.to_datetime(merged_df['created_at_inbound'])\n","merged_df['created_at_response'] = pd.to_datetime(merged_df['created_at_response'])\n","merged_df['response_time_minutes'] = (merged_df['created_at_response'] - merged_df['created_at_inbound']).dt.total_seconds() / 60\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaHHjt2WIMG5"},"outputs":[],"source":["merged_df['urgency'] = merged_df['response_time_minutes'].apply(\n","    lambda x: 'urgent' if pd.notnull(x) and x \u003c 60 else 'non-urgent'\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwXghQlNIQuj"},"outputs":[],"source":["import re\n","import string\n","\n","def preprocess_tweet(text):\n","    text = re.sub(r'@\\w+', '', text)\n","    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    text = text.lower()\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    return text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UwOTL5tIhoY"},"outputs":[],"source":["merged_df['clean_text'] = merged_df['text'].apply(preprocess_tweet)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n6noHbMwImoo"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers\u003c0.22,\u003e=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors\u003e=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill\u003c0.3.8,\u003e=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec\u003e=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]\u003e=2021.11.1-\u003edatasets) (2025.3.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: scipy\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1-\u003etorch) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (1.4.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (25.3.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (1.7.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (6.6.3)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (0.3.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp-\u003edatasets) (1.20.1)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.30.0-\u003etransformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (2.4.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (2025.6.15)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2-\u003etorch) (3.0.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003edatasets) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003edatasets) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003edatasets) (2025.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas-\u003edatasets) (1.17.0)\n"]}],"source":["pip install transformers datasets scikit-learn torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hnPw1GoPJOVE"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","merged_df['label'] = merged_df['urgency'].map({'non-urgent': 0, 'urgent': 1})\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    merged_df['clean_text'].tolist(),\n","    merged_df['label'].tolist(),\n","    test_size=0.2,\n","    random_state=42\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zNLW1FJrJUCF"},"outputs":[],"source":["from transformers import DistilBertTokenizerFast\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LhZdbEzcJik6"},"outputs":[],"source":["import torch\n","\n","class TweetDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        return {\n","            key: torch.tensor(val[idx])\n","            for key, val in self.encodings.items()\n","        } | {'labels': torch.tensor(self.labels[idx])}\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = TweetDataset(train_encodings, train_labels)\n","val_dataset = TweetDataset(val_encodings, val_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8EADrBV0JkMT"},"outputs":[],"source":["from transformers import DistilBertForSequenceClassification\n","\n","model = DistilBertForSequenceClassification.from_pretrained(\n","    'distilbert-base-uncased',\n","    num_labels=2\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBOZwYgYJshX"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=64,\n","    warmup_steps=100,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    evaluation_strategy='epoch',\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jm0e2GMkKLPF"},"outputs":[],"source":["import transformers\n","print(transformers.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtdHZ3ziKMsa"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=64,\n","    warmup_steps=100,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHSyxbzGKndw"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nl2M_aY-Kp1D"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fXMTZxXLvq-"},"outputs":[],"source":["trainer.evaluate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCwhrCQGMP5d"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = logits.argmax(axis=-1)\n","    return {\n","        \"accuracy\": accuracy_score(labels, preds),\n","        \"f1\": f1_score(labels, preds, average='weighted')\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcWz0GGkPBo7"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5jcJ9lbPU21"},"outputs":[],"source":["print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_XBXrb-P51p"},"outputs":[],"source":["{'eval_loss': 0.32, 'eval_runtime': 5.2}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jC43gUEHSrOw"},"outputs":[],"source":["!pip install streamlit\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClTHCQkRTBCk"},"outputs":[],"source":["pip install streamlit transformers torch seaborn matplotlib\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6CQRTv9UmlP"},"outputs":[],"source":["from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, pipeline\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S1POtqPcVApy"},"outputs":[],"source":["\n","import torch\n","import numpy as np\n","\n","@st.cache_resource\n","def load_model():\n","    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","    model = DistilBertForSequenceClassification.from_pretrained(\"your_model_dir\")  # Replace with your fine-tuned model directory\n","    return tokenizer, model\n","\n","tokenizer, model = load_model()\n","model.eval()\n","st.title(\"Tweet Urgency Classification\")\n","st.markdown(\"Classifies tweets as **urgent** or **non-urgent** based on response time prediction.\")\n","\n","tweet = st.text_area(\"Enter Tweet Text:\", \"\")\n","\n","if st.button(\"Predict Urgency\"):\n","    if tweet.strip() == \"\":\n","        st.warning(\"Please enter a tweet.\")\n","    else:\n","        inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True)\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            probs = torch.softmax(logits, dim=1).numpy()[0]\n","\n","        label = \"Urgent\" if np.argmax(probs) == 1 else \"Non-Urgent\"\n","        confidence = round(float(np.max(probs)) * 100, 2)\n","\n","        st.subheader(\"Prediction:\")\n","        st.success(f\"**{label}** (Confidence: {confidence}%)\")\n","        if st.checkbox(\"Show attention weights\"):\n","            with torch.no_grad():\n","                outputs_attn = model(**inputs, output_attentions=True)\n","                attentions = outputs_attn.attentions\n","                st.write(\"Attention layers output:\")\n","                for i, layer_attn in enumerate(attentions):\n","                    st.write(f\"Layer {i + 1} attention shape: {layer_attn.shape}\")\n","if st.checkbox(\"Show model summary\"):\n","    st.write(model)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMlQzAR9jAzQA6mQz+yJ/4w","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}